### 1. 机器学习的一些概念：
- 有监督：从标记的训练数据来推断一个功能的机器学习任务。
- 无监督：根据类别未知(没有被标记)的训练样本解决模式识别中的各种问题。
- 泛化能力：是指机器学习算法对新鲜样本的适应能力。
- 过拟合：为了得到一致假设而使假设变得过度严格。

解决方法：（1）在神经网络模型中，可使用权值衰减的方法，即每次迭代过程中以某个小因子降低每个权值。
（2）选取合适的停止训练标准，使对机器的训练在合适的程度；
（3）保留验证数据集，对训练成果进行验证；
（4）获取额外数据进行交叉验证；
（5）正则化，即在进行目标函数或代价函数优化时，在目标函数或代价函数后面加上一个正则项，一般有L1正则与L2正则等。

- 欠拟合：指模型拟合程度不高，数据距离拟合曲线较远，或指模型没有很好地捕捉到数据特征，不能够很好地拟合数据。

解决方法：（1）增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间；
（2）添加多项式特征，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强；
（3）减少正则化参数，正则化的目的是用来防止过拟合的，但是模型出现了欠拟合，则需要减少正则化参数；
（4）使用非线性模型，比如核SVM 、决策树、深度学习等模型；
（5）调整模型的容量(capacity)，通俗地，模型的容量是指其拟合各种函数的能力。

- 交叉验证：在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。

### 2. 线性回归的原理：
线性回归是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。

### 3. 线性回归损失函数、代价函数、目标函数
### 4. 优化方法(梯度下降法、牛顿法、拟牛顿法等)
### 5. 线性回归的评估指标
### 6. sklearn参数详解
